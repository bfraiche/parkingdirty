{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parking_dirty.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "YqbEOIkKO7R9",
        "_fIKMfosXara",
        "p14V6zJeW9tl",
        "pfuwuwbPXMTo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bfraiche/parkingdirty/blob/master/parking_dirty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YqbEOIkKO7R9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ]
    },
    {
      "metadata": {
        "id": "dH7wvkOJ5vaV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_fIKMfosXara",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ELT"
      ]
    },
    {
      "metadata": {
        "id": "q4Xhb_6s5-TB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nrows = 150\n",
        "ncolumns = 150\n",
        "channels = 3\n",
        "\n",
        "def read_and_process_image(list_of_images):\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for image in list_of_images:\n",
        "        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))\n",
        "        if 'not' in image:\n",
        "            y.append(1)\n",
        "        else:\n",
        "            y.append(0)\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tkkuq4y9z45O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pkngdrty \t= 'http://parkingdirty.com/BlockedBikeLaneTrainingSingleCam.zip'\n",
        "\n",
        "rPd = requests.get(pkngdrty)\n",
        "zPd = zipfile.ZipFile(io.BytesIO(rPd.content))\n",
        "zPd.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_gUIn6vE67s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# separate raw image files into training and test sets\n",
        "n_blocked = len([name for name in os.listdir('blocked')])\n",
        "n_unblocked = len([name for name in os.listdir('notblocked')])\n",
        "\n",
        "# make the training set have equal images for each class\n",
        "if(n_blocked >= n_unblocked):\n",
        "  n_train = round(n_unblocked*0.8)\n",
        "  n_test_ub = n_unblocked - n_train\n",
        "  n_test_b = n_blocked - n_train\n",
        "else:\n",
        "  n_train = round(n_blocked*0.8)\n",
        "  n_test_ub = n_unblocked - n_train\n",
        "  n_test_b = n_blocked - n_train\n",
        "\n",
        "train_blocked = ['blocked/{}'.format(i) for i in os.listdir('blocked')]\n",
        "train_notblocked = ['notblocked/{}'.format(i) for i in os.listdir('notblocked')]\n",
        "\n",
        "random.shuffle(train_blocked)\n",
        "random.shuffle(train_notblocked)\n",
        "\n",
        "train_imgs = train_blocked[:n_train] + train_notblocked[:n_train]\n",
        "\n",
        "test_imgs = train_blocked[n_test_b:] + train_notblocked[n_test_ub:]\n",
        "\n",
        "# format images for model\n",
        "X, y = read_and_process_image(train_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Vs-tx6lh2EI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9_ONj3_659-w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # clear memory\n",
        "# del X, y, train_imgs, train_blocked, train_notblocked, n_train, n_test_ub, n_test_b, n_blocked, n_unblocked, rPd, zPd\n",
        "# gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p14V6zJeW9tl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ]
    },
    {
      "metadata": {
        "id": "kJA3b7ZS591H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get the length of the train and validation data\n",
        "ntrain = len(X_train)\n",
        "nval = len(X_val)\n",
        "\n",
        "#We will use a batch size of 32. Note: batch size should be a factor of 2.***4,8,16,32,64...***\n",
        "batch_size = 32\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))  #Dropout for regularization\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,   #Scale the image between 0 and 1\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale\n",
        "\n",
        "#Create the image generators\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pfuwuwbPXMTo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "id": "Oaf366_H6RVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100, \n",
        "                              epochs=64,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLiYdrq06fTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot the train and val curve\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhMmX2go6fXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Save the model\n",
        "# model.save_weights('model_weights.h5')\n",
        "# model.save('model_keras.h5')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('model_keras.h5')\n",
        "# files.download('model_wieghts.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "poYLUUEeQ8QZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ]
    },
    {
      "metadata": {
        "id": "nWfpErFhvIhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3yzMSSwNqqf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))  #Dropout for regularization\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CEb2KlIvMGJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = load_model('model_keras.h5') # this doesn't work\n",
        "model.load_weights('model_wieghts.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhnxJGEGvTeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "metadata": {
        "id": "f0SZWwWKCv-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Failed to evaluate against the test set with a confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "g4XTp_cvNJOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wh_uIm7MCjZS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_imgs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhoTHzDQEE48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = cv2.resize(cv2.imread(test_imgs[0], cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC)\n",
        "y = 0\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzNL8JRHRvPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9njj1kRYDAxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = mpimg.imread(test_imgs[0])\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_FNAPBpWGeVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zz = test_datagen.flow(X, batch_size=1)\n",
        "print(zz)\n",
        "# pred = model.predict(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6FasXUrqT2n3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8VB-CuQC86e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict the first 10 images of the test set"
      ]
    },
    {
      "metadata": {
        "id": "Upd8or0k6fPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test, y_test = read_and_process_image(test_imgs[0:10]) #Y_test in this case will be empty.\n",
        "x = np.array(X_test)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvkeMqz56fLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "text_labels = []\n",
        "columns = 5\n",
        "plt.figure(figsize=(30,20))\n",
        "for batch in test_datagen.flow(x, batch_size=1):\n",
        "    pred = model.predict(batch)\n",
        "    if pred > 0.5:\n",
        "        text_labels.append('not blocked')\n",
        "    else:\n",
        "        text_labels.append('blocked')\n",
        "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
        "    plt.title('The lane is ' + text_labels[i])\n",
        "    imgplot = plt.imshow(batch[0])\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        break\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iV8XZESeRBAH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scratch"
      ]
    },
    {
      "metadata": {
        "id": "dJsKurewIlst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.listdir('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rbsL9Imf7AiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Critical Path:\n",
        "- Visualize false positives with prediction percentage\n",
        "- Train and test the model on the full dataset\n",
        "- Create heatmap or use LIME for interpretation"
      ]
    }
  ]
}