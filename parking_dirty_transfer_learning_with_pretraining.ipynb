{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parking dirty - transfer learning with pretraining.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbernstein/parkingdirty/blob/master/parking_dirty_transfer_learning_with_pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knj-cxsFR4BC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "3110acf0-4324-46f0-e9d5-42139b02058b"
      },
      "source": [
        "!git clone https://github.com/danbernstein/parkingdirty.git \n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models\n",
        "\n",
        "# download tensorboard\n",
        "#!pip install -q tf-nightly-2.0-preview --no-cache-dir\n",
        "!pip install pascal-voc-writer\n",
        "\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model \n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as k \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "\n",
        "# build CNN using tf.keras\n",
        "from tensorflow.keras import models # for building CNN (deep learning)\n",
        "from tensorflow.keras import layers # for building fully connected network\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "import datetime\n",
        "\n",
        "#exec(open(\"parkingdirty/object_detection/py/object_detection_functions.py\").read())\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'parkingdirty'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 542 (delta 21), reused 0 (delta 0), pack-reused 482\u001b[K\n",
            "Receiving objects: 100% (542/542), 9.27 MiB | 23.05 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 25872 (delta 1), reused 1 (delta 0), pack-reused 25865\u001b[K\n",
            "Receiving objects: 100% (25872/25872), 508.53 MiB | 16.83 MiB/s, done.\n",
            "Resolving deltas: 100% (15526/15526), done.\n",
            "Checking out files: 100% (2907/2907), done.\n",
            "Collecting pascal-voc-writer\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/82/dd86999e6062fc34478f11ead7a68e6615d7e270b39624547edd1dbaba76/pascal_voc_writer-0.1.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from pascal-voc-writer) (2.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->pascal-voc-writer) (1.1.1)\n",
            "Installing collected packages: pascal-voc-writer\n",
            "Successfully installed pascal-voc-writer-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6PR-2YZkOQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_data(cam):\n",
        "  import shutil\n",
        " # shutil.rmtree('object_detection/input_imgs/blocked')\n",
        " # shutil.rmtree('object_detection/input_imgs/notblocked')\n",
        "\n",
        "  if cam == \"single\":\n",
        "  \n",
        "# download and read in data\n",
        "    zip_address = 'http://parkingdirty.com/BlockedBikeLaneTrainingSingleCam.zip'\n",
        "  else:\n",
        "    zip_address = 'http://parkingdirty.com/BlockedBikeLaneTrainingFull.zip'\n",
        "  \n",
        "    import requests, zipfile, io\n",
        "    r = requests.get(zip_address)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall('object_detection/input_imgs') # extract images from zip to input_imgs folder\n",
        "    \n",
        "    print('data downloaded successfully')\n",
        "\n",
        "def read_resize_label_image(img, x_dim, y_dim):\n",
        "  import cv2\n",
        "   \n",
        "  img_orig = cv2.imread(img)\n",
        " # print(img_orig.size)\n",
        " # img_orig = cv2.cvtColor(img_orig, cv2.COLOR_RGB2HSV)\n",
        "  img_arrays = cv2.resize(img_orig, dsize=(x_dim, y_dim), interpolation=cv2.INTER_CUBIC)\n",
        "  \n",
        " # if the image file name contains \"not\" then assigned 0, otherwise 1, so 1 is blocked, 0 is notblocked\n",
        "  if img.find(\"not\") is not -1:\n",
        "      img_labels = 0\n",
        "  else:\n",
        "      img_labels = 1\n",
        "      \n",
        "  del img_orig\n",
        "   \n",
        "    \n",
        "  return img_arrays, img_labels\n",
        "\n",
        "\n",
        "def prep_data(input_shape_x = 300, input_shape_y = 300):\n",
        "  import numpy as np\n",
        "  # append the label at front, and assign to object\n",
        "  imgs_blocked = list(map('object_detection/input_imgs/blocked/{0}'.format, os.listdir('object_detection/input_imgs/blocked')))\n",
        "  imgs_notblocked = list(map('object_detection/input_imgs/notblocked/{0}'.format, os.listdir('object_detection/input_imgs/notblocked')))\n",
        "\n",
        "  # shuffle data\n",
        "  np.random.shuffle(imgs_blocked)\n",
        "  np.random.shuffle(imgs_notblocked)\n",
        "\n",
        "  print(\"number of blocked images: \", len(imgs_blocked))\n",
        "  print(\"number of not blocked images: \", len(imgs_notblocked))\n",
        "  print(\"ratio of classes: \", len(imgs_blocked)/len(imgs_notblocked))\n",
        "\n",
        "  # separate into training (contains training and validation), and test set\n",
        "  training_set = imgs_blocked[:int(round(0.8*len(imgs_blocked)))] + imgs_notblocked[:int(round(0.8*len(imgs_notblocked)))]\n",
        "  print(\"length of training set: \", len(training_set))\n",
        "\n",
        "  # keep 20% of the images for test set, there will also be a validation set later\n",
        "  test_set = imgs_blocked[int(round(0.8*len(imgs_blocked))):] + imgs_notblocked[int(round(0.8*len(imgs_notblocked))):]\n",
        "  print(\"length of test set: \", len(test_set))\n",
        "\n",
        "  del imgs_blocked\n",
        "  del imgs_notblocked\n",
        "  \n",
        "  # read and resize data\n",
        "  print(\"begin reading and resizing data\")\n",
        "  training_arrays, training_labels = zip(*[(read_resize_label_image(i, input_shape_x, input_shape_y)) for i in training_set])\n",
        "  test_arrays, test_labels = zip(*[(read_resize_label_image(i, input_shape_x, input_shape_y)) for i in test_set])\n",
        "  \n",
        "  print(\"finish data reading and resizing\")\n",
        "  del training_set\n",
        "  del test_set\n",
        "  \n",
        "  import pandas\n",
        "  print(\"training: \", pandas.Series(training_labels).value_counts())\n",
        "  print(\"test: \", pandas.Series(test_labels).value_counts())\n",
        "\n",
        "  import numpy as np\n",
        "  \n",
        "  # convert images and labels into numpy arrays \n",
        "\n",
        "  X_train_array = np.array(training_arrays)\n",
        "  Y_train_labels = np.array(training_labels)\n",
        "\n",
        "  del training_arrays\n",
        "  del training_labels\n",
        "\n",
        "  X_test_array = np.array(test_arrays)\n",
        "  Y_test_labels = np.array(test_labels)\n",
        "\n",
        "#  del test_arrays\n",
        "#  del test_labels\n",
        "  \n",
        "  # separate training data into training and validation sets\n",
        "  # we also have the test array that was held out earlier\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  print(\"splitting training data into training and validation\")\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(X_train_array, Y_train_labels, test_size = 0.2, \n",
        "                                                     shuffle = True)\n",
        "  \n",
        "  X_train //= 255\n",
        "  X_val //= 255\n",
        " \n",
        "\n",
        "  # confirm the size of the datasets\n",
        "  print(\"training images: \", len(X_train))\n",
        "  print(\"training labels: \", len(Y_train))\n",
        "  print(\"validation images: \", len(X_val))\n",
        "  print(\"validation labels: \", len(Y_val))\n",
        "  \n",
        "  print(\"data preparation complete\")\n",
        "  \n",
        "  return X_train, X_val, Y_train, Y_val, test_arrays, test_labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model(img_dim_x, img_dim_y):\n",
        "  from tensorflow.keras import applications\n",
        "  conv_base = applications.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(200,200,3))\n",
        "  conv_base.trainable = False\n",
        "  # define model to transfer learning from\n",
        "  # model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_dim_x, img_dim_y, 3))\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1024, activation=\"relu\"))\n",
        " # model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1024, activation=\"relu\"))\n",
        "  model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "  \n",
        "#  print(predictions)\n",
        "  \n",
        "#  model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "  # basic model \n",
        "  #model = models.Sequential()\n",
        "  #model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(img_dim_x, img_dim_y, 3)))\n",
        "  #model.add(layers.MaxPooling2D((2, 2)))\n",
        "  #model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  #model.add(layers.MaxPooling2D((2, 2)))\n",
        "  #model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  #model.add(layers.MaxPooling2D((2, 2)))\n",
        "  #model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  #model.add(layers.MaxPooling2D((2, 2)))\n",
        "  #model.add(layers.Flatten())\n",
        "  #model.add(layers.Dense(128, activation='relu'))\n",
        "  #model.add(layers.Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# create datagenerators for training and validation data\n",
        "\n",
        "def create_datagenerator():\n",
        "  train_datagen = ImageDataGenerator(rotation_range=40, # do not need rescale because we did it earlier\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,)\n",
        "  \n",
        "  val_datagen = ImageDataGenerator(rescale=1./255)  #We do not augment validation data. we only perform rescale\n",
        "\n",
        "  return train_datagen, val_datagen\n",
        "\n",
        "\n",
        "\n",
        "def train_model(img_dim_x, img_dim_y, train_datagen, val_datagen, X_train, Y_train, X_val, Y_val, batch_size = 64, epochs = 10):\n",
        "  \n",
        "  model = create_model(img_dim_x, img_dim_y)\n",
        "  \n",
        "  ## Compiler Includes Optimizer, and Learning Rate (LR), and Metrics\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                optimizer=optimizers.RMSprop(lr=1e-4), \n",
        "                metrics=['acc'])\n",
        "\n",
        "  logdir = os.path.join(\"logs/fit/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n",
        "  \n",
        "  early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "  model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                      validation_data = val_datagen.flow(X_val, Y_val, batch_size=batch_size),\n",
        "                      steps_per_epoch = X_train.shape[0] // batch_size,\n",
        "                      validation_steps = X_val.shape[0] // batch_size,\n",
        "                      epochs = 5,\n",
        "                      callbacks=[tensorboard_callback, early])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFDFS3cS70M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "c452e92d-cab8-4946-990b-59aaebe8e01c"
      },
      "source": [
        "# read and resize images, also store as X, Y with X as image array and Y as label\n",
        "#load_modules()\n",
        "download_data(cam = all)\n",
        "\n",
        "img_arrays = [] # images\n",
        "img_labels = [] # labels\n",
        "\n",
        "img_dim_x, img_dim_y  = 200, 200\n",
        "\n",
        "X_train, X_val, Y_train, Y_val, test_arrays, test_labels = prep_data(img_dim_x, img_dim_y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data downloaded successfully\n",
            "number of blocked images:  4131\n",
            "number of not blocked images:  3542\n",
            "ratio of classes:  1.166290231507623\n",
            "length of training set:  6139\n",
            "length of test set:  1534\n",
            "begin reading and resizing data\n",
            "finish data reading and resizing\n",
            "training:  1    3305\n",
            "0    2834\n",
            "dtype: int64\n",
            "test:  1    826\n",
            "0    708\n",
            "dtype: int64\n",
            "splitting training data into training and validation\n",
            "training images:  4911\n",
            "training labels:  4911\n",
            "validation images:  1228\n",
            "validation labels:  1228\n",
            "data preparation complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQZhFB1EFnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir logs/fit\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P59UtIb6KTgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen, val_datagen = create_datagenerator()\n",
        "\n",
        "train_model(img_dim_x, img_dim_y, train_datagen, val_datagen, X_train, Y_train, X_val, Y_val, batch_size = 64, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BomE7ke1jlYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## adjust model to increase capacity, currently sitting at 60% val accuracy\n",
        "\n",
        "def model_hyp(train_datagen, X_train, Y_train, X_val, Y_val):\n",
        "    from tf.keras.applications import InceptionResNetV2\n",
        "    \n",
        "    conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
        "    conv_base.trainable = False\n",
        "    \n",
        "    batch_size = 32\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(conv_base)\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer= {{choice(['rmsprop', 'adam'])}},\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    model.fit_generator(train_datagen.flow(X_train, Y_train,\n",
        "                        batch_size=batch_size),\n",
        "                        epochs = 50,\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        validation_data=(X_val, Y_val))\n",
        "        \n",
        "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
        "    \n",
        "    print('Val accuracy:', acc)\n",
        "    print('optimizer:', model.optimizer)\n",
        "\n",
        "    \n",
        "    K.clear_session()\n",
        "\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "\n",
        "  best_run, best_model = optim.minimize(model=model_hyp,\n",
        "                                        data=data,\n",
        "                                        algo=tpe.suggest,\n",
        "                                        max_evals=30,\n",
        "                                        trials=Trials(),\n",
        "                                        notebook_name='hyperas')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}