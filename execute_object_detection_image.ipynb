{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "execute_object_detection_image.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbernstein/parkingdirty/blob/master/execute_object_detection_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nRm7FPDnyujg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models\n",
        "!pip install shapely\n",
        "!pip install pascal-voc-writer\n",
        "\n",
        "!git clone https://github.com/danbernstein/parkingdirty.git "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-fNSUJb2Yo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shutil.rmtree('parkingdirty')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_E8hSbRzAb0",
        "colab_type": "code",
        "outputId": "d27a59b0-f56f-4c23-edf1-6fc1afaaba6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "exec(open(\"parkingdirty/object_detection_functions.py\").read())\n",
        "\n",
        "download_data()\n",
        "# set up the model\n",
        "detection_graph, label_map, categories, category_index = set_up_model('ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03')\n",
        "\n",
        "# run the detection and classification processing\n",
        "# args: detection_graph from set_up_model(), the input dir, output dir, threshold for obstacle detection, and number of images to process\n",
        "processimages(detection_graph, 'object_detection/input_imgs', 'object_detection/output_imgs', 0.3, 10, [(158,278),(126,272),(302,115),(310,116)])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model set up successfully\n",
            "starting processing\n",
            "2019-04-12 22:38:52.760983\n",
            "successfully run\n",
            "2019-04-12 22:39:45.413010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'object_detection/output_csv/csvfile.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "x7ONH6It7HBz",
        "colab_type": "code",
        "outputId": "aded8e7e-6357-4b3e-a0f6-fafb9f765524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "cell_type": "code",
      "source": [
        "get_optimal_threshold('object_detection/output_csv/csvfile.csv')\n",
        "get_misclassification('object_detection/output_csv/csvfile.csv', '20')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# A tibble: 11 x 3\n",
            "   threshold            tot_correct perc_correct\n",
            "   <chr>                      <dbl>        <dbl>\n",
            " 1 obstacle_25%                  18         0.9 \n",
            " 2 obstacle_30%                  18         0.9 \n",
            " 3 obstacle_35%                  17         0.85\n",
            " 4 obstacle_20%                  16         0.8 \n",
            " 5 obstacle_centerPoint          16         0.8 \n",
            " 6 obstacle_15%                  15         0.75\n",
            " 7 obstacle_40%                  15         0.75\n",
            " 8 obstacle_45%                  15         0.75\n",
            " 9 obstacle_10%                  14         0.7 \n",
            "10 obstacle_50%                  13         0.65\n",
            "11 obstacle_bikes                10         0.5 \n",
            "\n",
            "# A tibble: 20 x 5\n",
            "   image                                           label threshold   value match\n",
            "   <chr>                                           <dbl> <chr>       <dbl> <dbl>\n",
            " 1 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 2 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 3 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 4 object_detection/input_imgs/notblocked/2016-09…     0 obstacle_1…     1     0\n",
            " 5 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 6 object_detection/input_imgs/blocked/2016-10-05…     1 obstacle_1…     0     0\n",
            " 7 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 8 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            " 9 object_detection/input_imgs/notblocked/2016-09…     0 obstacle_1…     1     0\n",
            "10 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_1…     1     0\n",
            "11 object_detection/input_imgs/blocked/2016-10-05…     1 obstacle_1…     0     0\n",
            "12 object_detection/input_imgs/notblocked/2016-10…     0 obstacle_2…     1     0\n",
            "13 object_detection/input_imgs/notblocked/2016-09…     0 obstacle_2…     1     0\n",
            "14 object_detection/input_imgs/blocked/2016-09-28…     1 obstacle_2…     0     0\n",
            "15 object_detection/input_imgs/blocked/2016-10-05…     1 obstacle_2…     0     0\n",
            "16 object_detection/input_imgs/blocked/2016-09-28…     1 obstacle_2…     0     0\n",
            "17 object_detection/input_imgs/blocked/2016-10-05…     1 obstacle_2…     0     0\n",
            "18 object_detection/input_imgs/blocked/2016-09-28…     1 obstacle_3…     0     0\n",
            "19 object_detection/input_imgs/blocked/2016-10-05…     1 obstacle_3…     0     0\n",
            "20 object_detection/input_imgs/blocked/2016-09-28…     1 obstacle_3…     0     0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bfz6-Wg47NWd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_boxes('object_detection/input_imgs/blocked/2016-10-12 125255 cam135.png', detection_graph, 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}