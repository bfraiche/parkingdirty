{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "download_pd_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbernstein/parkingdirty/blob/master/object_detection/py/download_pd_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tWycOuYb2IhP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_data():\n",
        "# download and read in data\n",
        "  zip_address = 'http://parkingdirty.com/BlockedBikeLaneTrainingSingleCam.zip'\n",
        "\n",
        "  import requests, zipfile, io\n",
        "  r = requests.get(zip_address)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall('object_detection/input_imgs') # extract images from zip to input_imgs folder\n",
        "  \n",
        "  print('data downloaded successfully')\n",
        "\n",
        "\n",
        "# model download process\n",
        "\n",
        "# model to use : Faster RCNN Inception ResNet V2 built on coco\n",
        "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
        "# the function takes a tensorflow model as an argument, but the rest of the \n",
        "# set up code is specific to the coco dataset, so other pretrained model datasets \n",
        "# would need to be tweaked\n",
        "\n",
        "def set_up_model(model_name):\n",
        "  MODEL_NAME = model_name\n",
        "\n",
        "  MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "  DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "  # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "  PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "  # List of the strings that is used to add correct label for each box.\n",
        "  PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "  NUM_CLASSES = 90\n",
        "\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "  tar_file = tarfile.open(MODEL_FILE)\n",
        "  for file in tar_file.getmembers():\n",
        "    file_name = os.path.basename(file.name)\n",
        "    if 'frozen_inference_graph.pb' in file_name:\n",
        "      tar_file.extract(file, os.getcwd())\n",
        "\n",
        "  detection_graph = tf.Graph()\n",
        "  with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "      serialized_graph = fid.read()\n",
        "      od_graph_def.ParseFromString(serialized_graph)\n",
        "      tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "  label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "  category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "  # set image size for analysis\n",
        "  IMAGE_SIZE = (12, 8)\n",
        "  \n",
        "  print('model set up successfully')\n",
        "  \n",
        "  return detection_graph, label_map, categories, category_index\n",
        "\n",
        "\n",
        "# helper function to load images\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def set_up_detection(sess, detection_graph):\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # Definite input and output Tensors for detection_graph\n",
        "  image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "  # Each box represents a part of the image where a particular object was detected.\n",
        "  detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "  # score: confidence in the class prediction\n",
        "  detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "  # detected class\n",
        "  detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "  num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "  \n",
        "  return image_tensor, detection_boxes, detection_scores, detection_classes, num_detections\n",
        "\n",
        "\n",
        "def analyze_image(image_path, path_images_dir, sess, image_tensor, detection_boxes, detection_scores, detection_classes, num_detections):\n",
        "  \n",
        "  start_time = time.time()\n",
        "  timestamp = image_path.split(\".png\")[0]\n",
        "  img_name = timestamp.split(\"/\")[-1]\n",
        "\n",
        "\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  try:\n",
        "      image = Image.open(image_path)\n",
        "      image_np = load_image_into_numpy_array(image)\n",
        "  except IOError:\n",
        "    print(\"Issue opening \"+image_path)\n",
        "    \n",
        "    \n",
        "  width, height = image.size\n",
        "\n",
        "        \n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  \n",
        "  # if the image file name contains \"not\" then assigned 0, otherwise 1, so 1 is blocked, 0 is notblocked\n",
        "  if os.path.join(path_images_dir + \"/\" + image_path).find('not') is not -1:\n",
        "    img_labels = 0\n",
        "  else:\n",
        "    img_labels = 1 \n",
        "\n",
        "  # Actual detection\n",
        "  (boxes, scores, classes, num) = sess.run(\n",
        "      [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "      feed_dict={image_tensor: image_np_expanded}) \n",
        "  \n",
        "  \n",
        "  scores = np.squeeze(scores)\n",
        "  boxes = np.squeeze(boxes)\n",
        "  \n",
        "  return timestamp, img_name, img_labels, boxes, scores, classes, num\n",
        "\n",
        "\n",
        "def analyze_boxes(boxes, scores, classes, pathbikelane, f, threshold, timestamp, img_labels, num_cars_in_bikelane_01, num_cars_in_bikelane_015, \n",
        "        num_cars_in_bikelane_02, num_cars_in_bikelane_025, \n",
        "        num_cars_in_bikelane_03, num_cars_in_bikelane_035, \n",
        "        num_cars_in_bikelane_04, num_cars_in_bikelane_045,\n",
        "        num_cars_in_bikelane_05, num_cars_in_bike_lane_contains, \n",
        "        num_bikes_in_bike_lane):\n",
        "        for i in range(boxes.shape[0]):\n",
        "           if scores[i] > threshold:\n",
        "              box = tuple(boxes[i].tolist())\n",
        "              \n",
        "              classes_int = np.squeeze(classes).astype(np.int32)\n",
        "\n",
        "              if classes_int[i] in category_index.keys():\n",
        "                                  class_name = category_index[classes_int[i]]['name']  \n",
        "\n",
        "\n",
        "              ymin, xmin, ymax, xmax = box\n",
        "\n",
        "              # the box is given as a fraction of the distance in each dimension of the image\n",
        "              # so we have to multiple it by the image dimensions to get the center of each box, relative to the rest of the image\n",
        "              center_x = (((xmax * 352) - (xmin * 352)) / 2) + (xmin * 352) # x dimension of image\n",
        "              center_y = (((ymax * 288) - (ymin * 288)) / 2) + (ymin * 288) # y dimension of image\n",
        "              points = [(center_x, center_y)]\n",
        "              \n",
        "              # area of the object\n",
        "              obj_area =  ((xmax * 352) - (xmin * 352)) * ((ymax * 288) - (ymin * 288))\n",
        "              \n",
        "              # get the absolute position of the object in the image\n",
        "              p1 = Polygon([((xmax * 352),(ymax * 288)), ((xmin * 352),(ymax * 288)), ((xmin * 352),(ymin * 288)), ((xmax * 352),(ymin * 288))])\n",
        "              \n",
        "              # location of the bike lane\n",
        "              p2 = Polygon([(158,278),(126,272),(302,115),(310,116)])\n",
        "              \n",
        "              # get intersection between object and bike lane\n",
        "              p3 = p1.intersection(p2)\n",
        "              \n",
        "              # get ratio of overlap to total object area\n",
        "              overlap = p3.area / obj_area\n",
        "              \n",
        "\n",
        "              #print(class_name)\n",
        "              if class_name in {'car', 'truck', 'bus', 'motorcycle','train','person'}:\n",
        "                if overlap >= 0.1:\n",
        "                    num_cars_in_bikelane_01 += 1\n",
        "                if overlap >= 0.15:\n",
        "                    num_cars_in_bikelane_015 += 1\n",
        "                if overlap >= 0.2:\n",
        "                    num_cars_in_bikelane_02 += 1\n",
        "                if overlap >= 0.25:\n",
        "                    num_cars_in_bikelane_025 += 1\n",
        "                if overlap >= 0.3:\n",
        "                    num_cars_in_bikelane_03 += 1\n",
        "                if overlap >= 0.35:\n",
        "                    num_cars_in_bikelane_035 += 1\n",
        "                if overlap >= 0.4:\n",
        "                    num_cars_in_bikelane_04 += 1\n",
        "                if overlap >= 0.45:\n",
        "                    num_cars_in_bikelane_045 += 1\n",
        "                if overlap >= 0.5:\n",
        "                    num_cars_in_bikelane_05 += 1    \n",
        "                if pathbikelane.contains_points(points):\n",
        "                    num_cars_in_bike_lane_contains +=1\n",
        "              \n",
        "              if class_name == 'bicycle':\n",
        "                if pathbikelane.contains_points(points):\n",
        "                    num_bikes_in_bike_lane += 1    \n",
        "                    \n",
        " \n",
        "        f.write(timestamp + ',' + \n",
        "                str(num_cars_in_bikelane_01) + ',' +\n",
        "                str(num_cars_in_bikelane_015) + ',' +\n",
        "                str(num_cars_in_bikelane_02) + ',' +\n",
        "                str(num_cars_in_bikelane_025) + ',' +\n",
        "                str(num_cars_in_bikelane_03) + ',' +\n",
        "                str(num_cars_in_bikelane_035) + ',' +\n",
        "                str(num_cars_in_bikelane_04) + ',' +\n",
        "                str(num_cars_in_bikelane_045) + ',' +\n",
        "                str(num_cars_in_bikelane_05) + ',' + \n",
        "                str(num_cars_in_bike_lane_contains) + ',' + \n",
        "                str(num_bikes_in_bike_lane) + ',' + \n",
        "                str(img_labels) + '\\n')\n",
        "    \n",
        "    # return the data table\n",
        "        return f\n",
        "    \n",
        "    \n",
        "# clone dan bernstein's parkingdirty repo to access the R script for analysis\n",
        "  \n",
        "  \n",
        "def get_optimal_threshold(file):\n",
        "\n",
        "  command = 'Rscript'\n",
        "  path2script = 'parkingdirty/analyze_output.R'\n",
        "\n",
        "  args = [file]\n",
        "  cmd = [command, path2script] + args\n",
        "  x = subprocess.check_output(cmd, universal_newlines=True)\n",
        "\n",
        "  print(x)\n",
        "  \n",
        "  \n",
        "def get_misclassification(file, n):\n",
        "\n",
        "  command = 'Rscript'\n",
        "  path2script = 'parkingdirty/get_misclassification.R'\n",
        "\n",
        "  args = [file, n]\n",
        "  cmd = [command, path2script] + args\n",
        "  x = subprocess.check_output(cmd, universal_newlines=True)\n",
        "\n",
        "  print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J9MXIYgH4l5v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}