{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danbernstein/parkingdirty/blob/master/image_classification/py/hyperas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "q-b8sywacifv",
        "colab_type": "code",
        "outputId": "503baa17-c5b7-43e8-c174-b8503bbe334b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1565
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install pydrive\n",
        "! pip install hyperas\n",
        "! pip install hyperopt\n",
        "\n",
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# load modules\n",
        "import os # for accessing project file structure\n",
        "import requests # for downloading and loading data from the internet\n",
        "import zipfile # for unzipping zip files \n",
        "\n",
        "import numpy.random \n",
        "from matplotlib import pyplot # for plotting results\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Running setup.py bdist_wheel for pydrive ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n",
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/54/72/5533b6bf9b47dc33685c3e62c391d6eab5785a648a5ffa841e240a3db3fe/hyperas-0.4.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (6.0.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.3.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/e6/adb3be5576f5d27c6faa33f1e9fea8fe5dbd9351db12148de948507e352c/prompt_toolkit-2.0.7-py3-none-any.whl (338kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->hyperas) (1.1.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->hyperas) (40.6.3)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Building wheels for collected packages: hyperas\n",
            "  Running setup.py bdist_wheel for hyperas ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/38/3f/27826f57fae60ef788ceb47e2c649590ab8af31f42075325d2\n",
            "Successfully built hyperas\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.7 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: hyperas, prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "Successfully installed hyperas-0.4 prompt-toolkit-2.0.7\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [prompt_toolkit]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.1.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.7.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NGppCGvdVFuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def crop_img(img):\n",
        "    #polygon = [(180,300),(175,300),(290,150),(220,150)]\n",
        "\n",
        "    pts = np.array([[30,150],[70,150],[130,80],[90,80]])\n",
        "\n",
        "    ## (1) Crop the bounding rect\n",
        "    rect = cv2.boundingRect(pts)\n",
        "    x,y,w,h = rect\n",
        "    croped = img[y:y+h, x:x+w].copy()\n",
        "\n",
        "    ## (2) make mask\n",
        "    pts = pts - pts.min(axis=0)\n",
        "\n",
        "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
        "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "    ## (3) do bit-op\n",
        "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
        "\n",
        "    ## (4) add the white background\n",
        "    bg = np.ones_like(croped, np.uint8)*255\n",
        "    cv2.bitwise_not(bg,bg, mask=mask)\n",
        "    dst2 = bg+ dst\n",
        "\n",
        "    return dst2\n",
        "            \n",
        "\n",
        "def data():\n",
        "  \n",
        "  # download and read in data\n",
        "  zip_address = 'http://parkingdirty.com/BlockedBikeLaneTrainingFull.zip'\n",
        "  import numpy as np\n",
        "\n",
        "  import requests, zipfile, io\n",
        "  r = requests.get(zip_address)\n",
        "  z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "  z.extractall() \n",
        "  \n",
        "  # DATA PROCESSING\n",
        "  \n",
        "  # append the label at front, and assign to object\n",
        "  imgs_blocked = list(map('blocked/{0}'.format, os.listdir('blocked')))\n",
        "  imgs_notblocked = list(map('notblocked/{0}'.format, os.listdir('notblocked')))\n",
        "\n",
        "  # shuffle data\n",
        "  numpy.random.shuffle(imgs_blocked)\n",
        "  numpy.random.shuffle(imgs_notblocked)\n",
        "\n",
        "  print(\"number of blocked images: \", len(imgs_blocked))\n",
        "  print(\"number of not blocked images: \", len(imgs_notblocked))\n",
        "  print(\"ratio of classes: \", len(imgs_blocked)/len(imgs_notblocked))\n",
        "  \n",
        "  # separate into training (contains training and validation), and test set\n",
        "  training_set = imgs_blocked[:int(round(0.8*len(imgs_blocked)))] + imgs_notblocked[:int(round(0.8*len(imgs_notblocked)))]\n",
        "  print(len(training_set))\n",
        "\n",
        "  test_set = imgs_blocked[int(round(0.8*len(imgs_blocked))):] + imgs_notblocked[int(round(0.8*len(imgs_notblocked))):]\n",
        "  print(len(test_set))\n",
        "\n",
        "  del imgs_blocked\n",
        "  del imgs_notblocked\n",
        "  \n",
        "  import cv2\n",
        "\n",
        "  training_arrays = [] # images\n",
        "  training_labels = [] # labels\n",
        "  test_arrays = []\n",
        "  test_labels = []\n",
        "\n",
        "  \n",
        "  \n",
        "  for i in training_set:\n",
        "    img_orig = cv2.imread(i)\n",
        "    img_arrays = cv2.resize(img_orig, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "   # img_arrays = crop_img(img_arrays)\n",
        "    training_arrays.append(img_arrays)\n",
        "    \n",
        "    if i.find(\"not\") is not -1:\n",
        "      val = 0\n",
        "      training_labels.append(val)\n",
        "    else:\n",
        "      val = 1\n",
        "      training_labels.append(val)\n",
        "      \n",
        "  for i in test_set:\n",
        "    img_orig = cv2.imread(i)\n",
        "    img_arrays = cv2.resize(img_orig, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    test_arrays.append(img_arrays)\n",
        "    \n",
        "    if i.find(\"not\") is not -1:\n",
        "      val = 0\n",
        "      test_labels.append(val)\n",
        "    else:\n",
        "      val = 1\n",
        "      test_labels.append(val)\n",
        "  \n",
        "  del training_set\n",
        "  del test_set\n",
        "  \n",
        "  X_train_array = np.array(training_arrays)\n",
        "  Y_train_labels = np.array(training_labels)\n",
        "\n",
        "  del training_arrays\n",
        "  del training_labels\n",
        "\n",
        "  X_test_array = np.array(test_arrays)\n",
        "  Y_test_labels = np.array(test_labels)\n",
        "\n",
        "  del test_arrays\n",
        "  del test_labels\n",
        "  \n",
        "  # separate training data into training and validation sets\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(X_train_array, Y_train_labels, test_size = 0.2, \n",
        "                                                      shuffle = True)\n",
        "  \n",
        "  # only resize the image arrays, \"resizing\" the labels would give 1.0 validation accuracy, which is not true \n",
        "  X_train //= 255\n",
        "  X_val //= 255\n",
        "  \n",
        "  print(len(Y_train))\n",
        "  print(len(Y_val))\n",
        "  \n",
        "  train_datagen = ImageDataGenerator(rotation_range=40, # do not need rescale because we did it earlier\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,)\n",
        "\n",
        "\n",
        "  \n",
        "  return train_datagen, X_train, Y_train, X_val, Y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qljAsequysn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title = 'hyperas.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('hyperas.ipynb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JxfOZXxbbtF",
        "colab_type": "code",
        "outputId": "60cc5efe-0ea3-49b6-d848-b3207546f047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7415
        }
      },
      "cell_type": "code",
      "source": [
        "## adjust model to increase capacity, currently sitting at 60% val accuracy\n",
        "\n",
        "def model_hyp(train_datagen, X_train, Y_train, X_val, Y_val):\n",
        "    \n",
        "    batch_size = 64\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    #model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer= {{choice(['rmsprop', 'adam'])}},\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    model.fit_generator(train_datagen.flow(X_train, Y_train,\n",
        "                        batch_size=batch_size),\n",
        "                        epochs = 50,\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        validation_data=(X_val, Y_val))\n",
        "        \n",
        "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
        "    \n",
        "    print('Val accuracy:', acc)\n",
        "    print('optimizer:', model.optimizer)\n",
        "\n",
        "    \n",
        "    K.clear_session()\n",
        "\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "\n",
        "  best_run, best_model = optim.minimize(model=model_hyp,\n",
        "                                        data=data,\n",
        "                                        algo=tpe.suggest,\n",
        "                                        max_evals=30,\n",
        "                                        trials=Trials(),\n",
        "                                        notebook_name='hyperas')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Conv2D, MaxPooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.preprocessing.image import ImageDataGenerator\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import requests\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import zipfile\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy.random\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from matplotlib import pyplot\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import requests, zipfile, io\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import cv2\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam']),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: \n",
            "   3: # download and read in data\n",
            "   4: zip_address = 'http://parkingdirty.com/BlockedBikeLaneTrainingFull.zip'\n",
            "   5: import numpy as np\n",
            "   6: \n",
            "   7: import requests, zipfile, io\n",
            "   8: r = requests.get(zip_address)\n",
            "   9: z = zipfile.ZipFile(io.BytesIO(r.content))\n",
            "  10: z.extractall() \n",
            "  11: \n",
            "  12: # DATA PROCESSING\n",
            "  13: \n",
            "  14: # append the label at front, and assign to object\n",
            "  15: imgs_blocked = list(map('blocked/{0}'.format, os.listdir('blocked')))\n",
            "  16: imgs_notblocked = list(map('notblocked/{0}'.format, os.listdir('notblocked')))\n",
            "  17: \n",
            "  18: # shuffle data\n",
            "  19: numpy.random.shuffle(imgs_blocked)\n",
            "  20: numpy.random.shuffle(imgs_notblocked)\n",
            "  21: \n",
            "  22: print(\"number of blocked images: \", len(imgs_blocked))\n",
            "  23: print(\"number of not blocked images: \", len(imgs_notblocked))\n",
            "  24: print(\"ratio of classes: \", len(imgs_blocked)/len(imgs_notblocked))\n",
            "  25: \n",
            "  26: # separate into training (contains training and validation), and test set\n",
            "  27: training_set = imgs_blocked[:int(round(0.8*len(imgs_blocked)))] + imgs_notblocked[:int(round(0.8*len(imgs_notblocked)))]\n",
            "  28: print(len(training_set))\n",
            "  29: \n",
            "  30: test_set = imgs_blocked[int(round(0.8*len(imgs_blocked))):] + imgs_notblocked[int(round(0.8*len(imgs_notblocked))):]\n",
            "  31: print(len(test_set))\n",
            "  32: \n",
            "  33: del imgs_blocked\n",
            "  34: del imgs_notblocked\n",
            "  35: \n",
            "  36: import cv2\n",
            "  37: \n",
            "  38: training_arrays = [] # images\n",
            "  39: training_labels = [] # labels\n",
            "  40: test_arrays = []\n",
            "  41: test_labels = []\n",
            "  42: \n",
            "  43: \n",
            "  44: \n",
            "  45: for i in training_set:\n",
            "  46:   img_orig = cv2.imread(i)\n",
            "  47:   img_arrays = cv2.resize(img_orig, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
            "  48:  # img_arrays = crop_img(img_arrays)\n",
            "  49:   training_arrays.append(img_arrays)\n",
            "  50:   \n",
            "  51:   if i.find(\"not\") is not -1:\n",
            "  52:     val = 0\n",
            "  53:     training_labels.append(val)\n",
            "  54:   else:\n",
            "  55:     val = 1\n",
            "  56:     training_labels.append(val)\n",
            "  57:     \n",
            "  58: for i in test_set:\n",
            "  59:   img_orig = cv2.imread(i)\n",
            "  60:   img_arrays = cv2.resize(img_orig, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
            "  61:   \n",
            "  62:   test_arrays.append(img_arrays)\n",
            "  63:   \n",
            "  64:   if i.find(\"not\") is not -1:\n",
            "  65:     val = 0\n",
            "  66:     test_labels.append(val)\n",
            "  67:   else:\n",
            "  68:     val = 1\n",
            "  69:     test_labels.append(val)\n",
            "  70: \n",
            "  71: del training_set\n",
            "  72: del test_set\n",
            "  73: \n",
            "  74: X_train_array = np.array(training_arrays)\n",
            "  75: Y_train_labels = np.array(training_labels)\n",
            "  76: \n",
            "  77: del training_arrays\n",
            "  78: del training_labels\n",
            "  79: \n",
            "  80: X_test_array = np.array(test_arrays)\n",
            "  81: Y_test_labels = np.array(test_labels)\n",
            "  82: \n",
            "  83: del test_arrays\n",
            "  84: del test_labels\n",
            "  85: \n",
            "  86: # separate training data into training and validation sets\n",
            "  87: \n",
            "  88: from sklearn.model_selection import train_test_split\n",
            "  89: \n",
            "  90: X_train, X_val, Y_train, Y_val = train_test_split(X_train_array, Y_train_labels, test_size = 0.2, \n",
            "  91:                                                     shuffle = True)\n",
            "  92: \n",
            "  93: # only resize the image arrays, \"resizing\" the labels would give 1.0 validation accuracy, which is not true \n",
            "  94: X_train //= 255\n",
            "  95: X_val //= 255\n",
            "  96: \n",
            "  97: print(len(Y_train))\n",
            "  98: print(len(Y_val))\n",
            "  99: \n",
            " 100: train_datagen = ImageDataGenerator(rotation_range=40, # do not need rescale because we did it earlier\n",
            " 101:                                    width_shift_range=0.2,\n",
            " 102:                                    height_shift_range=0.2,\n",
            " 103:                                    shear_range=0.2,\n",
            " 104:                                    zoom_range=0.2,\n",
            " 105:                                    horizontal_flip=True,)\n",
            " 106: \n",
            " 107: \n",
            " 108: \n",
            " 109: \n",
            " 110: \n",
            " 111: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     \n",
            "   4:     batch_size = 64\n",
            "   5: \n",
            "   6:     model = Sequential()\n",
            "   7:     model.add(Conv2D(64, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
            "   8:     model.add(MaxPooling2D((2, 2)))\n",
            "   9:     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
            "  10:     model.add(MaxPooling2D((2, 2)))\n",
            "  11:     model.add(Conv2D(128, (3, 3), activation='relu'))\n",
            "  12:     model.add(MaxPooling2D((2, 2)))\n",
            "  13:     model.add(Conv2D(256, (3, 3), activation='relu'))\n",
            "  14:     model.add(MaxPooling2D((2, 2)))\n",
            "  15: \n",
            "  16:     #model.add(Dropout(0.5))\n",
            "  17: \n",
            "  18:     model.add(Flatten())\n",
            "  19:     model.add(Dense(256, activation='relu'))\n",
            "  20:     model.add(Dense(512, activation='relu'))\n",
            "  21:     model.add(Dense(1, activation='sigmoid'))\n",
            "  22: \n",
            "  23:     model.compile(loss='binary_crossentropy',\n",
            "  24:                   optimizer= space['optimizer'],\n",
            "  25:                   metrics=['accuracy'])\n",
            "  26:     \n",
            "  27:     model.fit_generator(train_datagen.flow(X_train, Y_train,\n",
            "  28:                         batch_size=batch_size),\n",
            "  29:                         epochs = 50,\n",
            "  30:                         steps_per_epoch=X_train.shape[0] // batch_size,\n",
            "  31:                         validation_data=(X_val, Y_val))\n",
            "  32:         \n",
            "  33:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
            "  34:     \n",
            "  35:     print('Val accuracy:', acc)\n",
            "  36:     print('optimizer:', model.optimizer)\n",
            "  37: \n",
            "  38:     \n",
            "  39:     K.clear_session()\n",
            "  40: \n",
            "  41:     return {'loss': -acc, 'status': STATUS_OK}\n",
            "  42: \n",
            "number of blocked images:  4131\n",
            "number of not blocked images:  3542\n",
            "ratio of classes:  1.166290231507623\n",
            "6139\n",
            "1534\n",
            "4911\n",
            "1228\n",
            "Epoch 1/50\n",
            "76/76 [==============================] - 31s 412ms/step - loss: 0.6900 - acc: 0.5514 - val_loss: 0.6754 - val_acc: 0.6262\n",
            "Epoch 2/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6862 - acc: 0.5684 - val_loss: 0.6713 - val_acc: 0.5570\n",
            "Epoch 3/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6808 - acc: 0.5659 - val_loss: 0.6603 - val_acc: 0.5822\n",
            "Epoch 4/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6772 - acc: 0.5645 - val_loss: 0.6681 - val_acc: 0.6246\n",
            "Epoch 5/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6808 - acc: 0.5768 - val_loss: 0.6678 - val_acc: 0.6091\n",
            "Epoch 6/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6740 - acc: 0.5846 - val_loss: 0.6562 - val_acc: 0.6189\n",
            "Epoch 7/50\n",
            "76/76 [==============================] - 28s 370ms/step - loss: 0.6770 - acc: 0.5752 - val_loss: 0.6602 - val_acc: 0.6287\n",
            "Epoch 8/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6745 - acc: 0.5861 - val_loss: 0.6593 - val_acc: 0.6262\n",
            "Epoch 9/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6674 - acc: 0.6034 - val_loss: 0.6593 - val_acc: 0.6287\n",
            "Epoch 10/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6733 - acc: 0.5850 - val_loss: 0.6637 - val_acc: 0.6156\n",
            "Epoch 11/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6725 - acc: 0.5933 - val_loss: 0.6691 - val_acc: 0.6148\n",
            "Epoch 12/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6690 - acc: 0.5982 - val_loss: 0.6463 - val_acc: 0.6360\n",
            "Epoch 13/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6714 - acc: 0.5911 - val_loss: 0.6469 - val_acc: 0.6262\n",
            "Epoch 14/50\n",
            "76/76 [==============================] - 28s 365ms/step - loss: 0.6701 - acc: 0.5902 - val_loss: 0.6492 - val_acc: 0.6360\n",
            "Epoch 15/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6679 - acc: 0.5910 - val_loss: 0.6668 - val_acc: 0.6393\n",
            "Epoch 16/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6653 - acc: 0.5992 - val_loss: 0.6620 - val_acc: 0.6262\n",
            "Epoch 17/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6715 - acc: 0.5822 - val_loss: 0.6567 - val_acc: 0.6197\n",
            "Epoch 18/50\n",
            "76/76 [==============================] - 28s 371ms/step - loss: 0.6701 - acc: 0.5936 - val_loss: 0.6587 - val_acc: 0.6401\n",
            "Epoch 19/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6709 - acc: 0.5884 - val_loss: 0.6534 - val_acc: 0.6262\n",
            "Epoch 20/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6660 - acc: 0.5995 - val_loss: 0.6882 - val_acc: 0.6295\n",
            "Epoch 21/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6676 - acc: 0.5956 - val_loss: 0.6669 - val_acc: 0.5953\n",
            "Epoch 22/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6679 - acc: 0.5958 - val_loss: 0.6451 - val_acc: 0.6238\n",
            "Epoch 23/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6683 - acc: 0.5904 - val_loss: 0.6460 - val_acc: 0.6352\n",
            "Epoch 24/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6637 - acc: 0.5998 - val_loss: 0.6476 - val_acc: 0.6368\n",
            "Epoch 25/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6663 - acc: 0.5947 - val_loss: 0.6541 - val_acc: 0.6287\n",
            "Epoch 26/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6643 - acc: 0.5951 - val_loss: 0.6517 - val_acc: 0.6319\n",
            "Epoch 27/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6661 - acc: 0.6001 - val_loss: 0.6527 - val_acc: 0.6401\n",
            "Epoch 28/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6654 - acc: 0.6006 - val_loss: 0.6465 - val_acc: 0.6393\n",
            "Epoch 29/50\n",
            "76/76 [==============================] - 28s 369ms/step - loss: 0.6663 - acc: 0.5954 - val_loss: 0.6567 - val_acc: 0.6376\n",
            "Epoch 30/50\n",
            "76/76 [==============================] - 28s 366ms/step - loss: 0.6644 - acc: 0.5996 - val_loss: 0.6467 - val_acc: 0.6417\n",
            "Epoch 31/50\n",
            "76/76 [==============================] - 28s 365ms/step - loss: 0.6633 - acc: 0.6050 - val_loss: 0.6412 - val_acc: 0.6384\n",
            "Epoch 32/50\n",
            "76/76 [==============================] - 28s 366ms/step - loss: 0.6639 - acc: 0.5968 - val_loss: 0.6449 - val_acc: 0.6344\n",
            "Epoch 33/50\n",
            "76/76 [==============================] - 28s 367ms/step - loss: 0.6649 - acc: 0.6065 - val_loss: 0.6450 - val_acc: 0.6344\n",
            "Epoch 34/50\n",
            "76/76 [==============================] - 28s 365ms/step - loss: 0.6604 - acc: 0.5986 - val_loss: 0.6596 - val_acc: 0.6352\n",
            "Epoch 35/50\n",
            "76/76 [==============================] - 28s 366ms/step - loss: 0.6664 - acc: 0.6021 - val_loss: 0.6452 - val_acc: 0.6441\n",
            "Epoch 36/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6636 - acc: 0.5985 - val_loss: 0.6432 - val_acc: 0.6262\n",
            "Epoch 37/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6602 - acc: 0.6087 - val_loss: 0.6398 - val_acc: 0.6368\n",
            "Epoch 38/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6620 - acc: 0.5965 - val_loss: 0.6510 - val_acc: 0.6376\n",
            "Epoch 39/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6703 - acc: 0.5875 - val_loss: 0.6409 - val_acc: 0.6433\n",
            "Epoch 40/50\n",
            "76/76 [==============================] - 28s 368ms/step - loss: 0.6551 - acc: 0.6106 - val_loss: 0.6556 - val_acc: 0.6401\n",
            "Epoch 41/50\n",
            "76/76 [==============================] - 28s 367ms/step - loss: 0.6668 - acc: 0.5973 - val_loss: 0.6450 - val_acc: 0.6262\n",
            "Epoch 42/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6656 - acc: 0.6006 - val_loss: 0.6417 - val_acc: 0.6393\n",
            "Epoch 43/50\n",
            "76/76 [==============================] - 27s 360ms/step - loss: 0.6580 - acc: 0.6102 - val_loss: 0.6445 - val_acc: 0.6327\n",
            "Epoch 44/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6606 - acc: 0.6040 - val_loss: 0.6457 - val_acc: 0.6287\n",
            "Epoch 45/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6607 - acc: 0.6140 - val_loss: 0.6424 - val_acc: 0.6262\n",
            "Epoch 46/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6585 - acc: 0.6034 - val_loss: 0.6495 - val_acc: 0.6482\n",
            "Epoch 47/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6612 - acc: 0.6088 - val_loss: 0.6427 - val_acc: 0.6458\n",
            "Epoch 48/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6622 - acc: 0.6037 - val_loss: 0.6402 - val_acc: 0.6368\n",
            "Epoch 49/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6579 - acc: 0.6134 - val_loss: 0.6396 - val_acc: 0.6401\n",
            "Epoch 50/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6596 - acc: 0.6150 - val_loss: 0.6442 - val_acc: 0.6482\n",
            "Val accuracy: 0.6482084688612226\n",
            "optimizer: <keras.optimizers.RMSprop object at 0x7ff48a1a8898>\n",
            "Epoch 1/50\n",
            "76/76 [==============================] - 29s 386ms/step - loss: 0.6916 - acc: 0.5382 - val_loss: 0.6780 - val_acc: 0.6254\n",
            "Epoch 2/50\n",
            "76/76 [==============================] - 28s 365ms/step - loss: 0.6820 - acc: 0.5795 - val_loss: 0.6642 - val_acc: 0.6360\n",
            "Epoch 3/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6781 - acc: 0.5783 - val_loss: 0.6574 - val_acc: 0.6287\n",
            "Epoch 4/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6761 - acc: 0.5857 - val_loss: 0.6571 - val_acc: 0.6327\n",
            "Epoch 5/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6729 - acc: 0.5942 - val_loss: 0.6632 - val_acc: 0.6059\n",
            "Epoch 6/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6718 - acc: 0.5917 - val_loss: 0.6587 - val_acc: 0.6238\n",
            "Epoch 7/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6748 - acc: 0.5837 - val_loss: 0.6551 - val_acc: 0.6352\n",
            "Epoch 8/50\n",
            "76/76 [==============================] - 27s 362ms/step - loss: 0.6731 - acc: 0.5863 - val_loss: 0.6517 - val_acc: 0.6336\n",
            "Epoch 9/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6690 - acc: 0.5982 - val_loss: 0.6552 - val_acc: 0.6238\n",
            "Epoch 10/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6693 - acc: 0.5928 - val_loss: 0.6624 - val_acc: 0.6173\n",
            "Epoch 11/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6721 - acc: 0.5919 - val_loss: 0.6501 - val_acc: 0.6336\n",
            "Epoch 12/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6694 - acc: 0.5978 - val_loss: 0.6548 - val_acc: 0.6221\n",
            "Epoch 13/50\n",
            "76/76 [==============================] - 28s 366ms/step - loss: 0.6697 - acc: 0.5962 - val_loss: 0.6609 - val_acc: 0.6164\n",
            "Epoch 14/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6713 - acc: 0.5828 - val_loss: 0.6514 - val_acc: 0.6262\n",
            "Epoch 15/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6679 - acc: 0.5944 - val_loss: 0.6512 - val_acc: 0.6246\n",
            "Epoch 16/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6698 - acc: 0.5879 - val_loss: 0.6569 - val_acc: 0.6221\n",
            "Epoch 17/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6677 - acc: 0.5970 - val_loss: 0.6471 - val_acc: 0.6287\n",
            "Epoch 18/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6693 - acc: 0.5881 - val_loss: 0.6542 - val_acc: 0.6238\n",
            "Epoch 19/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6732 - acc: 0.5782 - val_loss: 0.6468 - val_acc: 0.6287\n",
            "Epoch 20/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6640 - acc: 0.6025 - val_loss: 0.6517 - val_acc: 0.6262\n",
            "Epoch 21/50\n",
            "76/76 [==============================] - 28s 364ms/step - loss: 0.6677 - acc: 0.5888 - val_loss: 0.6517 - val_acc: 0.6295\n",
            "Epoch 22/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6665 - acc: 0.6002 - val_loss: 0.6464 - val_acc: 0.6303\n",
            "Epoch 23/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6628 - acc: 0.6020 - val_loss: 0.6704 - val_acc: 0.6384\n",
            "Epoch 24/50\n",
            "76/76 [==============================] - 28s 368ms/step - loss: 0.6688 - acc: 0.6000 - val_loss: 0.6457 - val_acc: 0.6360\n",
            "Epoch 25/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6684 - acc: 0.5953 - val_loss: 0.6456 - val_acc: 0.6466\n",
            "Epoch 26/50\n",
            "76/76 [==============================] - 28s 362ms/step - loss: 0.6645 - acc: 0.5933 - val_loss: 0.6526 - val_acc: 0.6205\n",
            "Epoch 27/50\n",
            "76/76 [==============================] - 27s 361ms/step - loss: 0.6660 - acc: 0.5938 - val_loss: 0.6492 - val_acc: 0.6360\n",
            "Epoch 28/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6679 - acc: 0.5989 - val_loss: 0.6456 - val_acc: 0.6360\n",
            "Epoch 29/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6644 - acc: 0.5979 - val_loss: 0.6544 - val_acc: 0.6441\n",
            "Epoch 30/50\n",
            "76/76 [==============================] - 28s 363ms/step - loss: 0.6678 - acc: 0.6002 - val_loss: 0.6355 - val_acc: 0.6458\n",
            "Epoch 31/50\n",
            "11/76 [===>..........................] - ETA: 17s - loss: 0.6450 - acc: 0.6264"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}